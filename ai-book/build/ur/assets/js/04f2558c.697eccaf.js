"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[150],{2124:i=>{i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"introduction","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/introduction/intro","label":"\u0641\u0632\u06cc\u06a9\u0644 \u0627\u06d2 \u0622\u0626\u06cc \u0627\u0648\u0631 \u06c1\u06cc\u0648\u0645\u06cc\u0646\u0627\u0626\u06cc\u0688 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u062f\u0631\u0633\u06cc \u06a9\u062a\u0627\u0628","docId":"introduction/intro","unlisted":false}]},{"type":"category","label":"ros2-foundations","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/ros2-foundations/module-1-ros2","label":"Module 1: The Robotic Nervous System - ROS 2","docId":"ros2-foundations/module-1-ros2","unlisted":false},{"type":"link","href":"/ur/docs/ros2-foundations/ros2-hands-on","label":"ROS 2 Core Concepts","docId":"ros2-foundations/ros2-hands-on","unlisted":false}]},{"type":"category","label":"simulation","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/simulation/digital-twins","label":"Digital Twins","docId":"simulation/digital-twins","unlisted":false},{"type":"link","href":"/ur/docs/simulation/gazebo-unity","label":"Gazebo & Unity Integration","docId":"simulation/gazebo-unity","unlisted":false},{"type":"link","href":"/ur/docs/simulation/module-2-simulation","label":"Module 2: Simulation & Digital Twins","docId":"simulation/module-2-simulation","unlisted":false}]},{"type":"category","label":"hardware-basics","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/hardware-basics/module-3-hardware","label":"Module 3: Hardware Foundations & Edge AI","docId":"hardware-basics/module-3-hardware","unlisted":false}]},{"type":"category","label":"vla-systems","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/vla-systems/module-4-vla-foundations","label":"Module 4: Vision-Language-Action (VLA) Systems - Foundations","docId":"vla-systems/module-4-vla-foundations","unlisted":false},{"type":"link","href":"/ur/docs/vla-systems/vla-action","label":"VLA Action Systems","docId":"vla-systems/vla-action","unlisted":false},{"type":"link","href":"/ur/docs/vla-systems/vla-hands-on-basic","label":"Hands-On: Basic VLA Agent (Design Only)","docId":"vla-systems/vla-hands-on-basic","unlisted":false},{"type":"link","href":"/ur/docs/vla-systems/vla-language","label":"VLA Language Systems","docId":"vla-systems/vla-language","unlisted":false},{"type":"link","href":"/ur/docs/vla-systems/vla-vision","label":"VLA Vision Systems","docId":"vla-systems/vla-vision","unlisted":false}]},{"type":"category","label":"advanced-ai-control","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/ur/docs/advanced-ai-control/module-5-advanced-ai","label":"Module 5: Advanced AI & Control","docId":"advanced-ai-control/module-5-advanced-ai","unlisted":false}]},{"type":"link","href":"/ur/docs/intro","label":"Physical AI & Humanoid Robotics Textbook","docId":"intro","unlisted":false}]},"docs":{"advanced-ai-control/module-5-advanced-ai":{"id":"advanced-ai-control/module-5-advanced-ai","title":"Module 5: Advanced AI & Control","description":"RL, sim-to-real, model-based control, and subagent architectures","sidebar":"tutorialSidebar"},"hardware-basics/module-3-hardware":{"id":"hardware-basics/module-3-hardware","title":"Module 3: Hardware Foundations & Edge AI","description":"Jetson kits, RealSense, sensor integration, and robot options","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"Physical AI & Humanoid Robotics Textbook","description":"A Docusaurus-powered curriculum for Physical AI, ROS 2, simulation, VLA systems and humanoid robotics","sidebar":"tutorialSidebar"},"introduction/intro":{"id":"introduction/intro","title":"\u0641\u0632\u06cc\u06a9\u0644 \u0627\u06d2 \u0622\u0626\u06cc \u0627\u0648\u0631 \u06c1\u06cc\u0648\u0645\u06cc\u0646\u0627\u0626\u06cc\u0688 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u062f\u0631\u0633\u06cc \u06a9\u062a\u0627\u0628","description":"\u0688\u0648\u06a9\u06cc \u0633\u0648\u0631\u0633 \u067e\u0631 \u0645\u0628\u0646\u06cc \u0646\u0635\u0627\u0628 \u062c\u0648 \u0641\u0632\u06cc\u06a9\u0644 \u0627\u06d2 \u0622\u0626\u06cc\u060c ROS 2\u060c \u0633\u0645\u06cc\u0648\u0644\u06cc\u0634\u0646\u060c VLA \u0633\u0633\u0679\u0645\u0632 \u0627\u0648\u0631 \u06c1\u06cc\u0648\u0645\u06cc\u0646\u0627\u0626\u06cc\u0688 \u0631\u0648\u0628\u0648\u0679\u06a9\u0633 \u067e\u0631 \u0645\u0628\u0646\u06cc \u06c1\u06d2","sidebar":"tutorialSidebar"},"ros2-foundations/module-1-ros2":{"id":"ros2-foundations/module-1-ros2","title":"Module 1: The Robotic Nervous System - ROS 2","description":"Mastering the middleware that makes modern humanoid robots think and move","sidebar":"tutorialSidebar"},"ros2-foundations/ros2-hands-on":{"id":"ros2-foundations/ros2-hands-on","title":"ROS 2 Core Concepts","description":"Nodes, Topics, Services, Actions, DDS \u2014 Deep and Practical Understanding","sidebar":"tutorialSidebar"},"simulation/digital-twins":{"id":"simulation/digital-twins","title":"Digital Twins","description":"Designing, maintaining and using digital twins for sim-to-real","sidebar":"tutorialSidebar"},"simulation/gazebo-unity":{"id":"simulation/gazebo-unity","title":"Gazebo & Unity Integration","description":"Using Gazebo for physics and Unity for high-quality rendering (static guidance)","sidebar":"tutorialSidebar"},"simulation/module-2-simulation":{"id":"simulation/module-2-simulation","title":"Module 2: Simulation & Digital Twins","description":"Physics simulation, Gazebo, Unity, and building digital twins","sidebar":"tutorialSidebar"},"vla-systems/module-4-vla-foundations":{"id":"vla-systems/module-4-vla-foundations","title":"Module 4: Vision-Language-Action (VLA) Systems - Foundations","description":"Empowering humanoids to perceive, understand, and interact with the world through multimodal AI","sidebar":"tutorialSidebar"},"vla-systems/vla-action":{"id":"vla-systems/vla-action","title":"VLA Action Systems","description":"Motion planning, IK, RL, task planning (design-level guidance)","sidebar":"tutorialSidebar"},"vla-systems/vla-hands-on-basic":{"id":"vla-systems/vla-hands-on-basic","title":"Hands-On: Basic VLA Agent (Design Only)","description":"A static, copy-paste friendly lab plan for a basic VLA interaction using simulated perception and text commands","sidebar":"tutorialSidebar"},"vla-systems/vla-language":{"id":"vla-systems/vla-language","title":"VLA Language Systems","description":"LLMs, instruction following, reasoning (static guidance)","sidebar":"tutorialSidebar"},"vla-systems/vla-vision":{"id":"vla-systems/vla-vision","title":"VLA Vision Systems","description":"Perception models, segmentation, ViT, scene understanding","sidebar":"tutorialSidebar"}}}}')}}]);